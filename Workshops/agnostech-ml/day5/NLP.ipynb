{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset for NLP\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fetch_20newsgroups(subset='train', remove=('headers', 'footers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=['news', 'target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news'] = train_data['data']\n",
    "df['target'] = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I was wondering if anyone out there could enli...\n",
       "1    A fair number of brave souls who upgraded thei...\n",
       "2    well folks, my mac plus finally gave up the gh...\n",
       "3    Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> a...\n",
       "4    From article <C5owCB.n3p@world.std.com>, by to...\n",
       "Name: news, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n&gt; a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  target\n",
       "0  I was wondering if anyone out there could enli...       7\n",
       "1  A fair number of brave souls who upgraded thei...       4\n",
       "2  well folks, my mac plus finally gave up the gh...       4\n",
       "3  Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> a...       1\n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...      14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"In order to feed predictive or clustering models with the text data\",\n",
    "    \"one first need to turn the text into vectors of numerical values suitable for statistical analysis\",\n",
    "    \"Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given\",\n",
    "    \"Remove accents and perform other character normalization during the preprocessing step\",\n",
    "    \"is a fast method that only works on characters that have\",\n",
    "    \"It is easy for a classifier to overfit on particular things that appear in the 20 Newsgroups data, such as newsgroup headers\",\n",
    "    \"Many classifiers achieve very high F-scores, but their results would not generalize to other documents that aren’t from this window of time\",\n",
    "    \"For example, let’s look at the results of a multinomial Naive Bayes classifier, which is fast to train and achieves a decent F-score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In order to feed predictive or clustering models with the text data',\n",
       " 'one first need to turn the text into vectors of numerical values suitable for statistical analysis',\n",
       " 'Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given',\n",
       " 'Remove accents and perform other character normalization during the preprocessing step',\n",
       " 'is a fast method that only works on characters that have',\n",
       " 'It is easy for a classifier to overfit on particular things that appear in the 20 Newsgroups data, such as newsgroup headers',\n",
       " 'Many classifiers achieve very high F-scores, but their results would not generalize to other documents that aren’t from this window of time',\n",
       " 'For example, let’s look at the results of a multinomial Naive Bayes classifier, which is fast to train and achieves a decent F-score']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_tran = tfidf.fit_transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.09861229, 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.09861229, 2.09861229, 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.09861229, 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.09861229, 2.5040774 , 2.5040774 ,\n",
       "       1.81093022, 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.09861229, 2.5040774 ,\n",
       "       2.5040774 , 1.58778666, 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.09861229,\n",
       "       2.5040774 , 1.58778666, 1.81093022, 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.09861229, 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.09861229,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.09861229, 1.58778666, 1.25131443,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 1.25131443,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 , 2.5040774 ,\n",
       "       2.5040774 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 38,\n",
       " 'order': 61,\n",
       " 'to': 84,\n",
       " 'feed': 28,\n",
       " 'predictive': 66,\n",
       " 'or': 60,\n",
       " 'clustering': 18,\n",
       " 'models': 47,\n",
       " 'with': 93,\n",
       " 'the': 79,\n",
       " 'text': 77,\n",
       " 'data': 20,\n",
       " 'one': 58,\n",
       " 'first': 29,\n",
       " 'need': 50,\n",
       " 'turn': 86,\n",
       " 'into': 40,\n",
       " 'vectors': 88,\n",
       " 'of': 56,\n",
       " 'numerical': 55,\n",
       " 'values': 87,\n",
       " 'suitable': 76,\n",
       " 'for': 30,\n",
       " 'statistical': 73,\n",
       " 'analysis': 4,\n",
       " 'instruction': 39,\n",
       " 'on': 57,\n",
       " 'what': 90,\n",
       " 'do': 22,\n",
       " 'if': 37,\n",
       " 'byte': 13,\n",
       " 'sequence': 72,\n",
       " 'is': 41,\n",
       " 'given': 33,\n",
       " 'analyze': 5,\n",
       " 'that': 78,\n",
       " 'contains': 19,\n",
       " 'characters': 15,\n",
       " 'not': 54,\n",
       " 'remove': 68,\n",
       " 'accents': 1,\n",
       " 'and': 6,\n",
       " 'perform': 65,\n",
       " 'other': 62,\n",
       " 'character': 14,\n",
       " 'normalization': 53,\n",
       " 'during': 24,\n",
       " 'preprocessing': 67,\n",
       " 'step': 74,\n",
       " 'fast': 27,\n",
       " 'method': 46,\n",
       " 'only': 59,\n",
       " 'works': 94,\n",
       " 'have': 34,\n",
       " 'it': 42,\n",
       " 'easy': 25,\n",
       " 'classifier': 16,\n",
       " 'overfit': 63,\n",
       " 'particular': 64,\n",
       " 'things': 81,\n",
       " 'appear': 7,\n",
       " '20': 0,\n",
       " 'newsgroups': 52,\n",
       " 'such': 75,\n",
       " 'as': 9,\n",
       " 'newsgroup': 51,\n",
       " 'headers': 35,\n",
       " 'many': 45,\n",
       " 'classifiers': 17,\n",
       " 'achieve': 2,\n",
       " 'very': 89,\n",
       " 'high': 36,\n",
       " 'scores': 71,\n",
       " 'but': 12,\n",
       " 'their': 80,\n",
       " 'results': 69,\n",
       " 'would': 95,\n",
       " 'generalize': 32,\n",
       " 'documents': 23,\n",
       " 'aren': 8,\n",
       " 'from': 31,\n",
       " 'this': 82,\n",
       " 'window': 92,\n",
       " 'time': 83,\n",
       " 'example': 26,\n",
       " 'let': 43,\n",
       " 'look': 44,\n",
       " 'at': 10,\n",
       " 'multinomial': 48,\n",
       " 'naive': 49,\n",
       " 'bayes': 11,\n",
       " 'which': 91,\n",
       " 'train': 85,\n",
       " 'achieves': 3,\n",
       " 'decent': 21,\n",
       " 'score': 70}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20',\n",
       " 'accents',\n",
       " 'achieve',\n",
       " 'achieves',\n",
       " 'analysis',\n",
       " 'analyze',\n",
       " 'and',\n",
       " 'appear',\n",
       " 'aren',\n",
       " 'as',\n",
       " 'at',\n",
       " 'bayes',\n",
       " 'but',\n",
       " 'byte',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'classifier',\n",
       " 'classifiers',\n",
       " 'clustering',\n",
       " 'contains',\n",
       " 'data',\n",
       " 'decent',\n",
       " 'do',\n",
       " 'documents',\n",
       " 'during',\n",
       " 'easy',\n",
       " 'example',\n",
       " 'fast',\n",
       " 'feed',\n",
       " 'first',\n",
       " 'for',\n",
       " 'from',\n",
       " 'generalize',\n",
       " 'given',\n",
       " 'have',\n",
       " 'headers',\n",
       " 'high',\n",
       " 'if',\n",
       " 'in',\n",
       " 'instruction',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'let',\n",
       " 'look',\n",
       " 'many',\n",
       " 'method',\n",
       " 'models',\n",
       " 'multinomial',\n",
       " 'naive',\n",
       " 'need',\n",
       " 'newsgroup',\n",
       " 'newsgroups',\n",
       " 'normalization',\n",
       " 'not',\n",
       " 'numerical',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'or',\n",
       " 'order',\n",
       " 'other',\n",
       " 'overfit',\n",
       " 'particular',\n",
       " 'perform',\n",
       " 'predictive',\n",
       " 'preprocessing',\n",
       " 'remove',\n",
       " 'results',\n",
       " 'score',\n",
       " 'scores',\n",
       " 'sequence',\n",
       " 'statistical',\n",
       " 'step',\n",
       " 'such',\n",
       " 'suitable',\n",
       " 'text',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'things',\n",
       " 'this',\n",
       " 'time',\n",
       " 'to',\n",
       " 'train',\n",
       " 'turn',\n",
       " 'values',\n",
       " 'vectors',\n",
       " 'very',\n",
       " 'what',\n",
       " 'which',\n",
       " 'window',\n",
       " 'with',\n",
       " 'works',\n",
       " 'would']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-965b16f42db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "tfidf.vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 38)\t0.27039635158906633\n",
      "  (0, 61)\t0.3226386292699499\n",
      "  (0, 84)\t0.16122599582824834\n",
      "  (0, 28)\t0.3226386292699499\n",
      "  (0, 66)\t0.3226386292699499\n",
      "  (0, 60)\t0.3226386292699499\n",
      "  (0, 18)\t0.3226386292699499\n",
      "  (0, 47)\t0.3226386292699499\n",
      "  (0, 93)\t0.3226386292699499\n",
      "  (0, 79)\t0.16122599582824834\n",
      "  (0, 77)\t0.27039635158906633\n",
      "  (0, 20)\t0.27039635158906633\n",
      "  (1, 84)\t0.13792349143640176\n",
      "  (1, 79)\t0.13792349143640176\n",
      "  (1, 77)\t0.23131510952214943\n",
      "  (1, 58)\t0.27600664516019446\n",
      "  (1, 29)\t0.27600664516019446\n",
      "  (1, 50)\t0.27600664516019446\n",
      "  (1, 86)\t0.27600664516019446\n",
      "  (1, 40)\t0.27600664516019446\n",
      "  (1, 88)\t0.27600664516019446\n",
      "  (1, 56)\t0.17501043345302084\n",
      "  (1, 55)\t0.27600664516019446\n",
      "  (1, 87)\t0.27600664516019446\n",
      "  (1, 76)\t0.27600664516019446\n",
      "  :\t:\n",
      "  (6, 31)\t0.22845015903937335\n",
      "  (6, 82)\t0.22845015903937335\n",
      "  (6, 92)\t0.22845015903937335\n",
      "  (6, 83)\t0.22845015903937335\n",
      "  (7, 84)\t0.12251624165002666\n",
      "  (7, 79)\t0.12251624165002666\n",
      "  (7, 56)\t0.15546025070060823\n",
      "  (7, 30)\t0.17730824400874548\n",
      "  (7, 41)\t0.15546025070060823\n",
      "  (7, 6)\t0.2054752062928011\n",
      "  (7, 27)\t0.2054752062928011\n",
      "  (7, 16)\t0.2054752062928011\n",
      "  (7, 69)\t0.2054752062928011\n",
      "  (7, 26)\t0.245174309925675\n",
      "  (7, 43)\t0.245174309925675\n",
      "  (7, 44)\t0.245174309925675\n",
      "  (7, 10)\t0.245174309925675\n",
      "  (7, 48)\t0.245174309925675\n",
      "  (7, 49)\t0.245174309925675\n",
      "  (7, 11)\t0.245174309925675\n",
      "  (7, 91)\t0.245174309925675\n",
      "  (7, 85)\t0.245174309925675\n",
      "  (7, 3)\t0.245174309925675\n",
      "  (7, 21)\t0.245174309925675\n",
      "  (7, 70)\t0.245174309925675\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_new = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vect_new_fit = vect_new.fit_transform(df['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_new_dense = vect_new_fit.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'DataFrametaFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-634b178d7dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m new_df = pd.DataFrametaFrame(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvect_new_dense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'DataFrametaFrame'"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrametaFrame(\n",
    "    data=vect_new_dense\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(\n",
    "    data=vect_new_dense\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>114741</th>\n",
       "      <th>114742</th>\n",
       "      <th>114743</th>\n",
       "      <th>114744</th>\n",
       "      <th>114745</th>\n",
       "      <th>114746</th>\n",
       "      <th>114747</th>\n",
       "      <th>114748</th>\n",
       "      <th>114749</th>\n",
       "      <th>114750</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       1       2       3       4       5       6       7       8       \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   9       ...  114741  114742  114743  114744  114745  114746  114747  \\\n",
       "0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   114748  114749  114750  \n",
       "0     0.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0  \n",
       "2     0.0     0.0     0.0  \n",
       "3     0.0     0.0     0.0  \n",
       "4     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 114751 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/miniconda3/envs/newml/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10building tree 2 of 10building tree 3 of 10building tree 4 of 10\n",
      "\n",
      "\n",
      "\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=None, verbose=2,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(new_df.iloc[:2000, :], df.iloc[:2000, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(new_df, df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
